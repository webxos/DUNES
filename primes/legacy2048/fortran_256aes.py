import torch
import numpy as np
from ctypes import cdll, c_int, c_void_p, c_size_t
from src.legacy_2048.aes_256 import AES256Encryptor

# Team Instruction: Implement Fortran 256-AES mode for numerical input processing.
# Use CUDA for tensor operations and call Fortran library for linear algebra, inspired by Emeagwaliâ€™s structured dataflow.
class Fortran256AES:
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.encryptor = AES256Encryptor()
        # Load compiled Fortran shared library
        self.fortran_lib = cdll.LoadLibrary("/lqsdk/lib/libquantum256.so")
        self.fortran_lib.init_quantum_array.argtypes = [c_void_p, c_size_t]
        self.fortran_lib.init_quantum_array.restype = c_void_p

    def process(self, data: torch.Tensor) -> torch.Tensor:
        """Processes input data with Fortran-based numerical prep and 256-bit AES encryption."""
        # Convert tensor to numpy for Fortran compatibility
        data_np = data.cpu().numpy().astype(np.float64)
        data_ptr = data_np.ctypes.data_as(c_void_p)
        size = c_size_t(data_np.size)

        # Call Fortran function for quantum array initialization
        result_ptr = self.fortran_lib.init_quantum_array(data_ptr, size)
        result_np = np.ctypeslib.as_array(result_ptr, shape=(data_np.size,)).copy()
        self.fortran_lib.free(result_ptr)  # Free Fortran-allocated memory

        # Convert back to CUDA tensor and encrypt
        result_tensor = torch.tensor(result_np, device=self.device)
        encrypted_data = self.encryptor.encrypt(result_tensor.cpu().numpy().tobytes())
        return torch.tensor(np.frombuffer(encrypted_data, dtype=np.uint8), device=self.device)

# Example usage
if __name__ == "__main__":
    fortran = Fortran256AES()
    input_data = torch.arange(1, 1000001, device="cuda")
    result = fortran.process(input_data)
    print(f"Fortran 256-AES output shape: {result.shape}")